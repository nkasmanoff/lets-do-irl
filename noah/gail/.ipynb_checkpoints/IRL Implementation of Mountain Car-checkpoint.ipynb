{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-implementing the GAIL algorithm on the expert data acquired to run mountain car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import os\n",
    "import gym\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter \n",
    "from utils.utils import *\n",
    "from utils.zfilter import *\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x136c0e4d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, hidden_size):\n",
    "        super(Actor, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, num_outputs)\n",
    "        \n",
    "    #    self.fc3.weight.data.mul_(0.1)\n",
    "      #  self.fc3.bias.data.mul_(0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        mu = self.fc3(x)\n",
    "        logstd = torch.zeros_like(mu)\n",
    "        std = torch.exp(logstd)\n",
    "        return mu, std\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, num_inputs, hidden_size):\n",
    "        super(Critic, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    #    self.fc3.weight.data.mul_(0.1)\n",
    "     #   self.fc3.bias.data.mul_(0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        v = self.fc3(x)\n",
    "        return v\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_inputs, hidden_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "      #  self.fc3.weight.data.mul_(0.1)\n",
    "     #   self.fc3.bias.data.mul_(0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        prob = torch.sigmoid(self.fc3(x))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "demonstrations = np.load('/Users/noahkasmanoff/Desktop/Projects/lets-do-irl/mountaincar/app/expert_demo/expert_demo.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "continuous_expert = []\n",
    "for i in range(demonstrations.shape[0]):\n",
    "    episode = []\n",
    "    for j in range(demonstrations.shape[1]):\n",
    "        demo = demonstrations[i,j,:]\n",
    "\n",
    "        if np.array_equal(demo[-2:],np.array([2,-1])):\n",
    "            a = 1.\n",
    "        else:\n",
    "            a = -1. \n",
    "        continuous_expert.append((demo[0], demo[1],a))\n",
    "  #  continuous_expert.append(episode)\n",
    "       # break\n",
    "        #(state[0], state[1], action)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "demonstrations = np.array(continuous_expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MountainCarContinuous-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.57040036], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "\n",
    "for i in range(demonstrations.shape[0]):\n",
    "        action = demonstrations[i,-1:]\n",
    "        s, r, done, _ = env.step(action)\n",
    "        env.render()\n",
    "        if done:\n",
    "            env.close()\n",
    "            env.reset()\n",
    "        \n",
    "       # break\n",
    "        #(state[0], state[1], action)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for training \n",
    "import torch\n",
    "import numpy as np\n",
    "from utils.utils import get_entropy, log_prob_density\n",
    "\n",
    "def train_discrim(discrim, memory, discrim_optim, demonstrations, discrim_update_num, clip_param):\n",
    "    \"\"\"\n",
    "    Training the discriminator. \n",
    "\n",
    "    Why? \n",
    "    Goal of discrim is to do bce loss on learner and expert.\n",
    "\n",
    "    Should go through step by step, but the idea is to make learner look bad? That way it improves  \n",
    "\n",
    "    \"\"\"\n",
    "    memory = np.array(memory)  # s a r s' tuple\n",
    "    states = np.vstack(memory[:, 0]) \n",
    "    actions = list(memory[:, 1]) #actions taken by actor/policy\n",
    "\n",
    "    states = torch.Tensor(states)\n",
    "    actions = torch.Tensor(actions)\n",
    "        \n",
    "    criterion = torch.nn.BCELoss() # classify\n",
    " \n",
    "    for _ in range(discrim_update_num):\n",
    "        learner = discrim(torch.cat([states, actions], dim=1)) #pass (s,a) through discriminator\n",
    "        demonstrations = torch.Tensor(demonstrations) # pass (s,a) of expert through discriminator\n",
    "        expert = discrim(demonstrations) #discrimator \"guesses\" whether or not these \n",
    "        # actions came from expert or learner\n",
    "\n",
    "        discrim_loss = criterion(learner, torch.ones((states.shape[0], 1))) + \\\n",
    "                        criterion(expert, torch.zeros((demonstrations.shape[0], 1)))\n",
    "                # discrim loss: predict agent is all wrong, get as close to 0, and predict expert is 1, getting as close to 1 as possible. \n",
    "        discrim_optim.zero_grad() # gan loss, it tries to always get it right. \n",
    "        discrim_loss.backward()\n",
    "        discrim_optim.step()\n",
    "\n",
    "        # take these steps, do it however many times specified. \n",
    "\n",
    "    expert_acc = ((discrim(demonstrations) < 0.5).float()).mean() #how often it realized the fake examples were fake\n",
    "    learner_acc = ((discrim(torch.cat([states, actions], dim=1)) > 0.5).float()).mean() #how often if predicted expert correctly. \n",
    "\n",
    "    return expert_acc, learner_acc # accuracy, it's the same kind, but because imbalanced better to look at separately. \n",
    " \n",
    "\n",
    "def train_actor_critic(actor, critic, memory, actor_optim, critic_optim, actor_critic_update_num, batch_size, clip_param):\n",
    "    \"\"\"\n",
    "    Using get gae, this is basically ppo . \n",
    "\n",
    "    It's somewhat straightforward, and trained with the irl reward which is \n",
    "    from that memory versus what would usually be the real rewa\n",
    "    \"\"\"\n",
    "    memory = np.array(memory) \n",
    "    # tuple of a regular old RL problem, but now reward is what the discriminator says. \n",
    "    states = np.vstack(memory[:, 0]) \n",
    "    actions = list(memory[:, 1]) \n",
    "    rewards = list(memory[:, 2])  #IRL Rewards? yes. \n",
    "    masks = list(memory[:, 3]) \n",
    "\n",
    "    # compute value of what happened, see if what we can get ius better. \n",
    "    old_values = critic(torch.Tensor(states))\n",
    "    #GAE aka estimate of Value + actual return roughtly \n",
    "    returns, advants = get_gae(rewards, masks, old_values, gamma, lamda)\n",
    "    \n",
    "    # pass states through actor, get corresponding actions\n",
    "    mu, std = actor(torch.Tensor(states))\n",
    "    # new mus and stds? \n",
    "    old_policy = log_prob_density(torch.Tensor(actions), mu, std) # sum of log probability\n",
    "    # of old actions\n",
    "\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    n = len(states)\n",
    "    arr = np.arange(n)\n",
    "\n",
    "    for _ in range(actor_critic_update_num):\n",
    "        np.random.shuffle(arr)\n",
    "\n",
    "        for i in range(n // batch_size): \n",
    "            batch_index = arr[batch_size * i : batch_size * (i + 1)]\n",
    "            #batch_index = torch.LongTensor(batch_index)\n",
    "            \n",
    "            inputs = torch.Tensor(states)[batch_index]\n",
    "            actions_samples = torch.Tensor(actions)[batch_index]\n",
    "            returns_samples = returns.unsqueeze(1)[batch_index]\n",
    "            advants_samples = advants.unsqueeze(1)[batch_index]\n",
    "            oldvalue_samples = old_values[batch_index].detach()\n",
    "        \n",
    "        \n",
    "            values = critic(inputs) #\n",
    "            clipped_values = oldvalue_samples + \\\n",
    "                             torch.clamp(values - oldvalue_samples,\n",
    "                                         -clip_param, \n",
    "                                         clip_param)\n",
    "            critic_loss1 = criterion(clipped_values, returns_samples)\n",
    "            critic_loss2 = criterion(values, returns_samples)\n",
    "            critic_loss = torch.max(critic_loss1, critic_loss2).mean()\n",
    "\n",
    "            loss, ratio, entropy = surrogate_loss(actor, advants_samples, inputs,\n",
    "                                         old_policy.detach(), actions_samples,\n",
    "                                         batch_index)\n",
    "            clipped_ratio = torch.clamp(ratio,\n",
    "                                        1.0 - clip_param,\n",
    "                                        1.0 + clip_param)\n",
    "            clipped_loss = clipped_ratio * advants_samples\n",
    "            actor_loss = -torch.min(loss, clipped_loss).mean()\n",
    "            #print(actor_loss,critic_loss,entropy)\n",
    "           # return actor_loss, critic_loss, entropy\n",
    "            loss = actor_loss + 0.5 * critic_loss - 0.001 * entropy\n",
    "           # asdf\n",
    "            #loss = loss.mean() #TODO\n",
    "            actor_optim.zero_grad()\n",
    "            loss.backward()\n",
    "            actor_optim.step()\n",
    "\n",
    "           # critic_optim.zero_grad()\n",
    "           # loss.backward() \n",
    "            critic_optim.step()\n",
    "\n",
    "           # loss.zero_grad()\n",
    "\n",
    "def get_gae(rewards, masks, values, gamma, lamda):\n",
    "    \"\"\"\n",
    "    How much better a particular action is in a particular state. \n",
    "    \n",
    "    Uses reward of current action + value function of that state-action pair, discount factor gamma, and then lamda to compute. \n",
    "    \"\"\"\n",
    "    rewards = torch.Tensor(rewards)\n",
    "    masks = torch.Tensor(masks)\n",
    "    returns = torch.zeros_like(rewards)\n",
    "    advants = torch.zeros_like(rewards)\n",
    "    \n",
    "    running_returns = 0\n",
    "    previous_value = 0\n",
    "    running_advants = 0\n",
    "\n",
    "    for t in reversed(range(0, len(rewards))):\n",
    "        running_returns = rewards[t] + (gamma * running_returns * masks[t])\n",
    "        returns[t] = running_returns\n",
    "\n",
    "        running_delta = rewards[t] + (gamma * previous_value * masks[t]) - \\\n",
    "                                        values.data[t]\n",
    "        previous_value = values.data[t]\n",
    "        \n",
    "        running_advants = running_delta + (gamma * lamda * \\\n",
    "                                            running_advants * masks[t])\n",
    "        advants[t] = running_advants\n",
    "\n",
    "    advants = (advants - advants.mean()) / advants.std()\n",
    "    return returns, advants\n",
    "\n",
    "def surrogate_loss(actor, advants, states, old_policy, actions, batch_index):\n",
    "    \"\"\"\n",
    "    The loss for PPO. Re-run through network, recomput policy from states\n",
    "    and see if this surrogate ratio is better. If it is, use as proximal policy update. It's very close to prior policy, but def better. \n",
    "    \n",
    "    Not sure this actually works though. Should not the new mu and stds be used to draw,\n",
    "    \n",
    "        When do we use get_action? Only once in main, I think it should be for all? \n",
    "    \"\"\"\n",
    "    mu, std = actor(states)\n",
    "    new_policy = log_prob_density(actions, mu, std)\n",
    "    old_policy = old_policy[batch_index]\n",
    "\n",
    "    ratio = torch.exp(new_policy - old_policy)\n",
    "    surrogate_loss = ratio * advants\n",
    "    entropy = get_entropy(mu, std)\n",
    "\n",
    "    return surrogate_loss, ratio, entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state size: 2\n",
      "action size: 1\n"
     ]
    }
   ],
   "source": [
    "# Normally args but not here :-)\n",
    "env_name = 'MountainCarContinuous-v0'\n",
    "load_model = None\n",
    "seed = 0\n",
    "render = True\n",
    "gamma = 0.99\n",
    "lamda = .98\n",
    "hidden_size = 32\n",
    "\n",
    "learning_rate = 3e-4\n",
    "clip_param = .2\n",
    "discrim_update_num = 2\n",
    "actor_critic_update_num = 10\n",
    "l2_rate = 1e-3\n",
    "total_sample_size = 1024\n",
    "batch_size = 64\n",
    "suspend_accu_exp = .95 # do not need to be this high typically, but seems likely it has to be for a simple env like mountain car cont.\n",
    "suspend_accu_gen = .95\n",
    "max_iter_num = 4000\n",
    "seed = 42\n",
    "logdir = 'logs'\n",
    "\n",
    "env = gym.make(env_name)\n",
    "    \n",
    "env.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "num_inputs = env.observation_space.shape[0]\n",
    "num_actions = env.action_space.shape[0]\n",
    "running_state = ZFilter((num_inputs,), clip=5) # huh? \n",
    "# oh wow. ZFilter is exactly what I do in capstone project, removing \"badtimes\"\n",
    "\n",
    "print('state size:', num_inputs) \n",
    "print('action size:', num_actions)\n",
    "\n",
    "#load agent stuff \n",
    "actor = Actor(num_inputs, num_actions, hidden_size)\n",
    "critic = Critic(num_inputs, hidden_size)\n",
    "discrim = Discriminator(num_inputs + num_actions, hidden_size)\n",
    "\n",
    "actor_optim = optim.Adam(actor.parameters(), lr=learning_rate)\n",
    "critic_optim = optim.Adam(critic.parameters(), lr=learning_rate, \n",
    "                          weight_decay=l2_rate) \n",
    "discrim_optim = optim.Adam(discrim.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demonstrations.shape (2000, 3)\n",
      "0:: 2 episode score is 749.52\n",
      "Expert: 65.00% | Learner: 14.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noahkasmanoff/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  app.launch_new_instance()\n",
      "/Users/noahkasmanoff/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:53: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:: 4 episode score is 749.11\n",
      "Expert: 65.00% | Learner: 20.17%\n",
      "2:: 6 episode score is 748.06\n",
      "Expert: 65.00% | Learner: 22.12%\n",
      "3:: 8 episode score is 751.61\n",
      "Expert: 65.00% | Learner: 21.07%\n",
      "4:: 10 episode score is 756.70\n",
      "Expert: 65.00% | Learner: 22.07%\n",
      "5:: 12 episode score is 762.23\n",
      "Expert: 65.00% | Learner: 18.22%\n",
      "6:: 14 episode score is 662.94\n",
      "Expert: 65.15% | Learner: 19.30%\n",
      "7:: 16 episode score is 704.03\n",
      "Expert: 70.30% | Learner: 22.48%\n",
      "8:: 18 episode score is 595.89\n",
      "Expert: 74.95% | Learner: 28.95%\n",
      "9:: 20 episode score is 760.55\n",
      "Expert: 77.75% | Learner: 23.27%\n",
      "10:: 22 episode score is 761.80\n",
      "Expert: 79.90% | Learner: 22.47%\n",
      "11:: 24 episode score is 760.88\n",
      "Expert: 81.55% | Learner: 25.83%\n",
      "12:: 26 episode score is 759.83\n",
      "Expert: 83.25% | Learner: 29.13%\n",
      "13:: 28 episode score is 752.06\n",
      "Expert: 84.80% | Learner: 36.04%\n",
      "14:: 30 episode score is 756.67\n",
      "Expert: 86.25% | Learner: 27.28%\n",
      "15:: 32 episode score is 703.29\n",
      "Expert: 87.85% | Learner: 38.24%\n",
      "16:: 34 episode score is 627.33\n",
      "Expert: 89.30% | Learner: 41.89%\n",
      "17:: 36 episode score is 747.78\n",
      "Expert: 90.90% | Learner: 30.53%\n",
      "18:: 38 episode score is 612.65\n",
      "Expert: 92.20% | Learner: 39.60%\n",
      "19:: 40 episode score is 734.06\n",
      "Expert: 93.40% | Learner: 42.69%\n",
      "20:: 42 episode score is 745.07\n",
      "Expert: 94.35% | Learner: 34.78%\n",
      "21:: 44 episode score is 742.06\n",
      "Expert: 94.70% | Learner: 35.19%\n",
      "22:: 46 episode score is 741.42\n",
      "Expert: 94.60% | Learner: 30.93%\n",
      "23:: 48 episode score is 742.39\n",
      "Expert: 94.30% | Learner: 39.24%\n",
      "24:: 50 episode score is 741.21\n",
      "Expert: 93.40% | Learner: 37.39%\n",
      "25:: 52 episode score is 739.95\n",
      "Expert: 92.30% | Learner: 33.78%\n",
      "26:: 54 episode score is 735.09\n",
      "Expert: 91.10% | Learner: 34.63%\n",
      "27:: 56 episode score is 735.27\n",
      "Expert: 89.50% | Learner: 35.84%\n",
      "28:: 58 episode score is 730.71\n",
      "Expert: 88.00% | Learner: 37.04%\n",
      "29:: 60 episode score is 728.32\n",
      "Expert: 86.75% | Learner: 40.74%\n"
     ]
    }
   ],
   "source": [
    "# load demonstrations\n",
    "#expert_demo, _ = pickle.load(open('./expert_demo/expert_demo.p', \"rb\"))\n",
    "#demonstrations = np.load('/Users/noahkasmanoff/Desktop/Projects/lets-do-irl/mountaincar/app/expert_demo/expert_demo.npy')\n",
    "print(\"demonstrations.shape\", demonstrations.shape)\n",
    "\n",
    "writer = SummaryWriter(logdir)\n",
    "\n",
    "#if you aren't starting from scratch, load in this \n",
    "if load_model is not None:\n",
    "    saved_ckpt_path = os.path.join(os.getcwd(), 'save_model', str(load_model))\n",
    "    ckpt = torch.load(saved_ckpt_path)\n",
    "\n",
    "    # initialize everything\n",
    "    actor.load_state_dict(ckpt['actor'])\n",
    "    critic.load_state_dict(ckpt['critic'])\n",
    "    discrim.load_state_dict(ckpt['discrim'])\n",
    "\n",
    "    running_state.rs.n = ckpt['z_filter_n']\n",
    "    running_state.rs.mean = ckpt['z_filter_m']\n",
    "    running_state.rs.sum_square = ckpt['z_filter_s']\n",
    "\n",
    "    print(\"Loaded OK ex. Zfilter N {}\".format(running_state.rs.n))\n",
    "\n",
    "# if no old model no worries, start training. \n",
    "episodes = 0\n",
    "train_discrim_flag = True\n",
    "\n",
    "for iter in range(max_iter_num):\n",
    "    # for i total trajectories \n",
    "    actor.eval(), critic.eval()\n",
    "    memory = deque()\n",
    "\n",
    "    steps = 0\n",
    "    scores = []\n",
    "\n",
    "    while steps < total_sample_size: \n",
    "        # sample trajectories  (batch size)\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "\n",
    "        state = running_state(state) #uh.. again ZFilter related, cleans the state \n",
    "\n",
    "        for _ in range(10000): \n",
    "            #run through environment\n",
    "            if render: \n",
    "                env.render()\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            mu, std = actor(torch.Tensor(state).unsqueeze(0)) #pass state through actor network\n",
    "            action = get_action(mu, std)[0] #compute random action\n",
    "            next_state, reward, done, _ = env.step(action) #take a step\n",
    "            irl_reward = get_reward(discrim, state, action) #infer what the reward of this action is based on discriminator's get reward \n",
    "\n",
    "            if done:\n",
    "                mask = 0\n",
    "            else:\n",
    "                mask = 1 #if done, save this, \n",
    "\n",
    "            memory.append([state, action, irl_reward, mask])\n",
    "\n",
    "            next_state = running_state(next_state) #save cleaned next state\n",
    "            state = next_state #and set to current state, \n",
    "\n",
    "            score += irl_reward #add total reward\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "            #actual sampling done here \n",
    "\n",
    "\n",
    "\n",
    "        episodes += 1\n",
    "        scores.append(score)\n",
    "\n",
    "    score_avg = np.mean(scores) #how this model did, \n",
    "    print('{}:: {} episode score is {:.2f}'.format(iter, episodes, score_avg))\n",
    "    writer.add_scalar('log/score', float(score_avg), iter) #logg\n",
    "\n",
    "    actor.train(), critic.train(), discrim.train() #now train \n",
    "    if train_discrim_flag: #if this batch optimizes discrim/reward, \n",
    "        # for training the discriminator, classify where state-action pair came from. \n",
    "        expert_acc, learner_acc = train_discrim(discrim, memory, discrim_optim, demonstrations, discrim_update_num, clip_param) # see comments in train_model. \n",
    "        print(\"Expert: %.2f%% | Learner: %.2f%%\" % (expert_acc * 100, learner_acc * 100))\n",
    "        if expert_acc > suspend_accu_exp and learner_acc > suspend_accu_gen:\n",
    "            print(\"Now it will only train the policy, seeing as it is good enough at finding the differences between learner and expert trajectories.\")\n",
    "            train_discrim_flag = False #now restart, train policy. \n",
    "    #for training actor critic \n",
    "    \n",
    "    # PPO operation, \n",
    "    train_actor_critic(actor, critic, memory, actor_optim, critic_optim, actor_critic_update_num, batch_size, clip_param) # no output, see comments in train_model \n",
    "\n",
    "    if iter % 100:\n",
    "        score_avg = int(score_avg)\n",
    "\n",
    "        model_path = os.path.join(os.getcwd(),'save_model')\n",
    "        if not os.path.isdir(model_path):\n",
    "            os.makedirs(model_path)\n",
    "\n",
    "        ckpt_path = os.path.join(model_path, 'ckpt_'+ str(score_avg)+'.pth.tar')\n",
    "\n",
    "        save_checkpoint({\n",
    "            'actor': actor.state_dict(),\n",
    "            'critic': critic.state_dict(),\n",
    "            'discrim': discrim.state_dict(),\n",
    "            'z_filter_n':running_state.rs.n,\n",
    "            'z_filter_m': running_state.rs.mean,\n",
    "            'z_filter_s': running_state.rs.sum_square,\n",
    "           # 'args': args,\n",
    "            'score': score_avg\n",
    "        }, filename=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07768273802321382 [0.8813781]\n",
      "-0.07079025515486458 [-0.84136945]\n",
      "-0.011777408798640554 [-0.3431823]\n",
      "-0.0913131420254306 [0.9555791]\n",
      "-0.05513787550683134 [0.7425488]\n",
      "-0.08861107267631817 [-0.94133455]\n",
      "-0.01167586575240911 [-0.34169966]\n",
      "-0.07868711899854795 [0.8870576]\n",
      "-0.08919153635654312 [-0.9444127]\n",
      "-0.07993595119163643 [0.8940691]\n",
      "-0.0571821065451573 [0.7561885]\n",
      "-0.00948909140466734 [-0.3080437]\n",
      "-0.03614946014977818 [-0.6012442]\n",
      "-0.06357657699496144 [-0.7973492]\n",
      "-0.05034484630042222 [-0.709541]\n",
      "-0.0954963119903912 [0.97722214]\n",
      "-0.011634805610469812 [0.3410983]\n",
      "-0.01782829842499476 [-0.4222357]\n",
      "-0.06445337769436357 [-0.8028286]\n",
      "-0.04980844765909218 [0.705751]\n",
      "-0.008052801482618666 [0.28377458]\n",
      "-0.08029230782772744 [-0.89605975]\n",
      "-0.08959235249210594 [-0.94653237]\n",
      "-0.0021475220949876083 [0.14654426]\n",
      "-0.006996388769920614 [-0.26450688]\n",
      "-0.01889074393851553 [-0.43463483]\n",
      "-0.08583565669096381 [-0.92647535]\n",
      "-0.08609299713725704 [0.9278631]\n",
      "-0.06976143184864583 [-0.8352331]\n",
      "-0.052876822011290875 [-0.7271645]\n",
      "-0.03700812844720112 [-0.60834306]\n",
      "-0.08763275239381621 [-0.93612367]\n",
      "-0.05794845310270489 [0.7612388]\n",
      "-0.03175668312656512 [0.5635307]\n",
      "-0.0020145194779041197 [-0.14193377]\n",
      "-0.03039820875092261 [0.5513457]\n",
      "-0.01897342334782559 [-0.43558493]\n",
      "-0.015527721267396634 [0.3940523]\n",
      "-0.001992526534941508 [-0.14115688]\n",
      "-0.016133340927831342 [0.4016633]\n",
      "-0.02733385043966905 [-0.52281785]\n",
      "-0.05307890353499403 [-0.7285527]\n",
      "-0.012072683739374757 [0.34745768]\n",
      "-0.07077016667962113 [-0.84125006]\n",
      "-0.0891805936471485 [-0.9443548]\n",
      "-0.06544702234177749 [0.80899334]\n",
      "-0.00035656969205832975 [0.05971346]\n",
      "-0.02030113798208646 [-0.45056784]\n",
      "-0.024762680775760604 [0.49762115]\n",
      "-0.032553868904892626 [0.57056]\n",
      "-0.039902445659413394 [0.6316838]\n",
      "-0.09553083226908399 [0.97739875]\n",
      "-0.09667992425173431 [0.9832595]\n",
      "-0.001882056846353919 [-0.13718808]\n",
      "-7.810462479263729e-07 [-0.00279472]\n",
      "-0.011853580124230323 [0.3442903]\n",
      "-0.001683829880792942 [-0.12976247]\n",
      "-0.04470267078088455 [-0.66860056]\n",
      "-0.09079940865746927 [0.95288724]\n",
      "-0.015338908537319541 [-0.3916492]\n",
      "-0.09725689941506631 [-0.9861891]\n",
      "-4.8444093853947453e-05 [0.02201002]\n",
      "-0.061763833647063754 [-0.7858997]\n",
      "-0.005604080099743669 [-0.23672938]\n",
      "-0.05755418713519909 [0.75864476]\n",
      "-0.027041584953644816 [0.52001524]\n",
      "-0.036206621157566586 [-0.6017194]\n",
      "-0.08409309695817094 [-0.9170229]\n",
      "-0.007177722321952107 [-0.26791272]\n",
      "-0.005945537021997205 [-0.24383472]\n",
      "-0.0016396714593478246 [-0.12804966]\n",
      "-0.0723917298902407 [0.8508333]\n",
      "-0.05235812179041979 [0.7235891]\n",
      "-0.029270919306839362 [0.54102606]\n",
      "-0.09867361093726892 [0.9933459]\n",
      "-0.06241996753910009 [0.7900631]\n",
      "-0.082375612700233 [0.9076101]\n",
      "-0.012332122948528569 [0.35117123]\n",
      "-0.0002511679430213576 [-0.05011666]\n",
      "-0.023290049091437837 [0.48259765]\n",
      "-0.052562719524135916 [0.7250015]\n",
      "-0.05022186886116664 [-0.7086739]\n",
      "-0.04627050975361868 [0.6802243]\n",
      "-0.04197760129203268 [-0.64790124]\n",
      "-0.08125946548470644 [0.9014403]\n",
      "-0.03793467355660916 [0.6159113]\n",
      "-0.002241430203084449 [-0.14971407]\n",
      "-0.00024039758201893082 [-0.04903036]\n",
      "-0.008785547498122525 [0.29640424]\n",
      "-0.013710140594756927 [-0.37027207]\n",
      "-0.00922629631730878 [-0.3037482]\n",
      "-0.006765009129190958 [0.2600963]\n",
      "-0.0010753032670408004 [0.10369683]\n",
      "-0.008706612462356133 [-0.2950697]\n",
      "-0.08765365531576351 [0.9362353]\n",
      "-0.001086911709175681 [0.10425506]\n",
      "-0.00016667984956173637 [-0.04082644]\n",
      "-0.03500014923543517 [0.59160924]\n",
      "-0.05380783061050956 [0.7335382]\n",
      "-0.03813960704405908 [0.6175727]\n",
      "-0.0050132013070142145 [0.2239018]\n",
      "-0.046782267195357365 [0.68397564]\n",
      "-0.011643887225989503 [0.3412314]\n",
      "-0.03972363713251639 [0.6302669]\n",
      "-0.029517188142671458 [0.54329723]\n",
      "-0.0321847641857417 [0.5673162]\n",
      "-0.0725903590484677 [0.85199976]\n",
      "-0.059656210865697196 [-0.77237433]\n",
      "-0.08775914538384236 [0.9367985]\n",
      "-9.35639821761234e-05 [-0.03058823]\n",
      "-0.05070653141645529 [-0.7120852]\n",
      "-0.01706808910878488 [0.41313544]\n",
      "-0.008645383997358013 [0.29403034]\n",
      "-0.05325942736551639 [0.72979057]\n",
      "-0.0028664696579255634 [-0.16930652]\n",
      "-0.005807246606133277 [-0.2409823]\n",
      "-0.03979398585275682 [-0.63082474]\n",
      "-0.0019658757095968094 [0.14020969]\n",
      "-0.05526197768666777 [-0.743384]\n",
      "-0.0012247731883020807 [0.11066947]\n",
      "-0.0016137991407738862 [-0.1270354]\n",
      "-0.09644470245743585 [0.98206264]\n",
      "-0.028220389083857357 [-0.53122866]\n",
      "-0.026540692327060713 [0.5151766]\n",
      "-0.022701641289535335 [0.4764624]\n",
      "-0.001496191357159976 [0.1223189]\n",
      "-0.08050173398514496 [-0.8972276]\n",
      "-8.650462120658766e-05 [0.02941167]\n",
      "-0.040361734979582314 [-0.63530886]\n",
      "-8.135063803930281e-05 [0.02852203]\n",
      "-0.004165646850590599 [-0.20409916]\n",
      "-0.08857597504317916 [0.9411481]\n",
      "-0.09004927400214094 [0.94894296]\n",
      "-0.046688229820625794 [-0.68328786]\n",
      "-0.0882247428485755 [0.9392803]\n",
      "-0.0326421182421214 [0.5713328]\n",
      "-0.07488118617698235 [0.86533916]\n",
      "-0.00372367509969076 [-0.19296826]\n",
      "-0.06908321126801163 [0.8311631]\n",
      "-0.0642298240274286 [-0.8014351]\n",
      "-0.0057911783327986525 [-0.24064867]\n",
      "-0.08075084944625957 [0.89861476]\n",
      "-0.003410535944397908 [-0.18467636]\n",
      "-0.01921807635431927 [-0.43838426]\n",
      "-0.08717391944502176 [0.93366975]\n",
      "-0.02550520862141639 [-0.5050268]\n",
      "-0.00040993274806294113 [0.06402599]\n",
      "-0.002645788382325187 [0.1626588]\n",
      "-0.01354965257217069 [-0.36809853]\n",
      "-0.003257176224540004 [-0.18047649]\n",
      "-2.1620079393783187e-06 [-0.00464974]\n",
      "-0.0904079469675935 [-0.95083094]\n",
      "-0.0033988235067035967 [-0.18435898]\n",
      "-0.09296984598017986 [0.9642087]\n",
      "-0.002402330971353095 [0.15499455]\n",
      "-0.005784197886125698 [-0.2405036]\n",
      "-0.05656380787167024 [0.75208914]\n",
      "-0.03988608408630832 [-0.6315543]\n",
      "-0.03144079507567312 [0.5607209]\n",
      "-0.014276902051499098 [-0.37784788]\n",
      "-0.041593909370962835 [0.6449334]\n",
      "-0.09671483363228539 [0.983437]\n",
      "-0.014525944835981708 [-0.38112918]\n",
      "-0.00631462863948542 [-0.25128925]\n",
      "-0.018239857836250907 [-0.42708147]\n",
      "-0.09375169049528723 [-0.96825457]\n",
      "-1.5045306044091881e-05 [0.01226593]\n",
      "-0.05952380805972588 [-0.77151674]\n",
      "-0.007240342791887145 [-0.26907885]\n",
      "-0.020231520042877895 [-0.44979462]\n",
      "-0.031031425349561916 [0.5570586]\n",
      "-0.07935649919750745 [0.89082265]\n",
      "-0.005299616671724384 [-0.23020896]\n",
      "-0.014233401200581232 [0.3772718]\n",
      "-0.09128530358892172 [0.9554334]\n",
      "-5.486435281476833e-05 [-0.02342314]\n",
      "-0.04260433651345466 [0.65272]\n",
      "-0.005209930592807966 [0.22825272]\n",
      "-0.04002871486783058 [0.6326825]\n",
      "-0.06384170414253845 [-0.79901004]\n",
      "-0.06179889612681713 [0.78612274]\n",
      "-0.05274742024492732 [-0.7262742]\n",
      "-0.056155348931611476 [-0.7493687]\n",
      "-0.06955023990410361 [0.83396786]\n",
      "-0.048964765209399276 [0.6997483]\n",
      "-0.004574649123401642 [-0.2138843]\n",
      "-0.032246316013445055 [-0.5678584]\n",
      "-0.05159233577189895 [-0.71827805]\n",
      "-0.011022153781930744 [-0.3319963]\n",
      "-0.02240281617791915 [0.47331613]\n",
      "-0.07678933976579039 [-0.87629527]\n",
      "-0.009758214941154454 [-0.31238142]\n",
      "-0.005783240338987228 [-0.24048369]\n",
      "-0.06884428292829058 [-0.82972455]\n",
      "-0.011298114846489682 [-0.3361267]\n",
      "-0.02670195132943185 [0.5167393]\n",
      "-0.06385376328839953 [0.7990855]\n",
      "-0.056839737179146615 [0.75392133]\n",
      "-0.08749069424091119 [0.9353646]\n",
      "-0.02979393156935295 [0.5458382]\n",
      "-0.01806167266720218 [-0.42499027]\n",
      "-0.09260153297801176 [0.9622969]\n",
      "-0.0929915829031959 [-0.96432143]\n",
      "-0.05476031898544989 [0.74000216]\n",
      "-0.09731203247256169 [-0.9864686]\n",
      "-0.018400268915873232 [-0.42895535]\n",
      "-0.030805934653655245 [0.55503094]\n",
      "-0.06144406546833956 [-0.78386265]\n",
      "-0.044270238785472676 [0.66535884]\n",
      "-0.0900893805051183 [-0.94915426]\n",
      "-0.0003418379718823417 [-0.05846691]\n",
      "-0.021187032711458276 [0.46029374]\n",
      "-0.008543928174873372 [0.2923]\n",
      "-0.040895860090040516 [-0.6394987]\n",
      "-0.035104427947473836 [-0.5924899]\n",
      "-0.06412992006990273 [-0.8008116]\n",
      "-0.04482647997251413 [0.6695258]\n",
      "-0.04452473501653778 [-0.6672686]\n",
      "-0.0396568713777711 [-0.629737]\n",
      "-0.01121276249844252 [0.33485463]\n",
      "-0.006684835841783698 [-0.2585505]\n",
      "-0.07838574790813624 [0.88535726]\n",
      "-0.06273081796185274 [-0.7920279]\n",
      "-0.02213887802828305 [0.4705197]\n",
      "-0.07562924811628627 [0.8696508]\n",
      "-0.0021654603313969512 [-0.14715503]\n",
      "-0.011576041957575 [-0.34023583]\n",
      "-0.002113414579343331 [0.14537588]\n",
      "-0.013901707869285929 [0.37284994]\n",
      "-0.0033466059077552623 [0.18293731]\n",
      "-0.038090385607734235 [-0.6171741]\n",
      "-0.02446040413141226 [0.4945746]\n",
      "-0.0952077417994449 [-0.97574455]\n",
      "-0.050403336115783764 [-0.70995307]\n",
      "-0.057651557123492486 [-0.7592862]\n",
      "-0.0497453769943391 [0.705304]\n",
      "-0.06611551320262131 [0.81311446]\n",
      "-0.04736135750680184 [-0.6881959]\n",
      "-0.042910648408565066 [-0.6550622]\n",
      "-0.021028059891833453 [-0.45856363]\n",
      "-0.01192543731811071 [-0.34533226]\n",
      "-0.07613327035071507 [0.8725438]\n",
      "-0.003606032761127054 [0.18989557]\n",
      "-0.05837446333562788 [0.7640318]\n",
      "-0.0447441979205454 [0.66891104]\n",
      "-0.0916787379993739 [0.95749015]\n",
      "-7.325762101546702e-05 [0.02706615]\n",
      "-0.0921505433029072 [0.95995075]\n",
      "-0.020135052831279057 [0.448721]\n",
      "-0.07983010834889229 [0.89347696]\n",
      "-0.04407487504938992 [0.6638891]\n",
      "-0.03183195370378513 [-0.56419814]\n",
      "-0.04158569877296295 [0.64486974]\n",
      "-0.053439368780914265 [0.73102236]\n",
      "-0.023126591789444095 [-0.48090115]\n",
      "-0.00022761198283154929 [-0.0477087]\n",
      "-0.08209481444169456 [0.9060619]\n",
      "-0.09164868694746389 [0.9573332]\n",
      "-0.04296235141301033 [0.6554567]\n",
      "-0.008926115069807228 [0.29876605]\n",
      "-0.0007717159876367897 [0.08784737]\n",
      "-0.04249530855588866 [-0.65188426]\n",
      "-0.007845177942447013 [0.28009245]\n",
      "-0.08239324952001006 [-0.9077073]\n",
      "-0.0923428371753289 [0.9609518]\n",
      "-0.053742896386879485 [0.73309547]\n",
      "-0.048133648467643654 [0.6937842]\n",
      "-0.009163826788614049 [0.30271813]\n",
      "-0.08369172536701833 [-0.9148318]\n",
      "-0.0803288653287737 [0.8962637]\n",
      "-0.08950174597732855 [0.9460536]\n",
      "-0.08929401609544244 [0.9449551]\n",
      "-0.01514740897384792 [0.38919672]\n",
      "-0.03362909535101153 [0.579906]\n",
      "-0.0010339283642522513 [-0.10168227]\n",
      "-0.0005132055779750788 [0.07163837]\n",
      "-0.0009358372439767005 [-0.09673868]\n",
      "-0.030933712096567947 [-0.55618083]\n",
      "-0.05832683837475692 [0.7637201]\n",
      "-0.01726149528327392 [-0.41546956]\n",
      "-0.015286000459184735 [0.39097315]\n",
      "-0.018987666662448888 [0.4357484]\n",
      "-0.01528133772127669 [0.39091352]\n",
      "-0.04221842724065006 [0.6497571]\n",
      "-0.05886711927460056 [0.7672491]\n",
      "-0.060521397522905224 [0.777955]\n",
      "-0.09747581879301528 [0.9872984]\n",
      "-0.03481143875655022 [-0.5900122]\n",
      "-0.011762395335337406 [0.3429635]\n",
      "-0.001877959516495964 [0.13703866]\n",
      "-0.002641107178882241 [-0.16251484]\n",
      "-0.004273280498345167 [-0.20671915]\n",
      "-0.00032445372682360504 [0.05696084]\n",
      "-0.07058638384407914 [0.84015703]\n",
      "-0.07214721308777286 [0.84939516]\n",
      "-0.004865590307968426 [-0.22058083]\n",
      "-0.07942970520853124 [0.89123344]\n",
      "-0.0215364608988339 [0.46407393]\n",
      "-0.00017117867428029232 [-0.04137374]\n",
      "-0.042664824339775365 [-0.65318316]\n",
      "-0.011336210855052632 [-0.3366929]\n",
      "-0.01534155820829506 [0.391683]\n",
      "-0.0005022069670090945 [0.07086656]\n",
      "-0.031698419444268565 [0.5630135]\n",
      "-0.014923289187845601 [-0.38630673]\n",
      "-0.004099547249271774 [-0.20247339]\n",
      "-0.014987426895663703 [0.38713598]\n",
      "-0.09696346070592235 [-0.98470026]\n",
      "-0.00986996448041424 [-0.314165]\n",
      "-0.0003940047845341077 [0.0627698]\n",
      "-0.074666475706454 [0.86409765]\n",
      "-0.003153820726504031 [-0.17759]\n",
      "-0.00789530211571341 [-0.2809858]\n",
      "-0.005770123625029044 [0.24021082]\n",
      "-0.013532991782757 [-0.36787215]\n",
      "-0.01616353266837587 [0.40203896]\n",
      "-0.0695007292519577 [0.833671]\n",
      "-0.03167557041594051 [0.56281054]\n",
      "-0.011939429903600286 [-0.3455348]\n",
      "-0.07090464224794212 [-0.84204894]\n",
      "-0.006790563471339795 [-0.2605871]\n",
      "-0.0285306866943845 [0.53414124]\n",
      "-0.000936232838500417 [0.09675913]\n",
      "-0.09742907588674009 [-0.9870617]\n",
      "-0.00019648510726911206 [0.04432664]\n",
      "-0.0854466491561201 [-0.92437357]\n",
      "-0.05750200748443604 [0.7583008]\n",
      "-0.06780727968162524 [-0.82345176]\n",
      "-0.004273817113084367 [0.20673212]\n",
      "-0.05091297449212249 [-0.7135333]\n",
      "-0.03956417600244358 [-0.6290006]\n",
      "-0.005191796073673616 [0.22785513]\n",
      "-0.07191321872574151 [0.8480166]\n",
      "-0.0020121902918121214 [-0.1418517]\n",
      "-0.016956080466572133 [0.41177762]\n",
      "-0.013379764349156976 [0.3657836]\n",
      "-0.03558315672697212 [0.5965162]\n",
      "-0.0033857031061393043 [-0.1840028]\n",
      "-0.0029621290020822367 [0.17210837]\n",
      "-0.08947628243040527 [-0.94591904]\n",
      "-0.05084975217318153 [-0.7130901]\n",
      "-0.07286884616310695 [0.8536325]\n",
      "-0.010974212925208705 [-0.3312735]\n",
      "-0.025998983825070356 [-0.509892]\n",
      "-0.07140714864905853 [0.8450275]\n",
      "-0.04694096509883963 [-0.68513477]\n",
      "-0.05771710786127962 [0.75971776]\n",
      "-0.07384871789540491 [-0.85935277]\n",
      "-0.00190847449745013 [-0.13814755]\n",
      "-0.07993120839238976 [0.89404255]\n",
      "-0.07001543042659684 [0.83675224]\n",
      "-0.06580182069797616 [0.8111832]\n",
      "-0.018563426419564523 [-0.43085295]\n",
      "-0.004628489901081801 [0.21513925]\n",
      "-0.06235593020937955 [-0.7896577]\n",
      "-0.00694129986331129 [-0.26346347]\n",
      "-0.01681427905607649 [0.41005218]\n",
      "-0.07682240571739385 [0.8764839]\n",
      "-0.08757410806689202 [0.9358104]\n",
      "-0.02710773838832701 [0.5206509]\n",
      "-0.059413630693940435 [0.7708024]\n",
      "-0.07675952905169972 [0.87612516]\n",
      "-0.06341692440622958 [0.79634744]\n",
      "-0.08146435962636503 [0.9025761]\n",
      "-0.04484551755968483 [-0.66966796]\n",
      "-0.06122391341005482 [-0.7824571]\n",
      "-0.027143233376172304 [-0.5209917]\n",
      "-0.020870075113477073 [0.45683777]\n",
      "-0.009973431524258914 [0.3158074]\n",
      "-0.0141245160752427 [0.37582597]\n",
      "-0.008289663824791038 [0.28791776]\n",
      "-0.0589990647999926 [0.7681085]\n",
      "-0.026991631184968414 [-0.5195347]\n",
      "-0.005711729981716674 [-0.23899226]\n",
      "-0.05657752607322095 [0.75218034]\n",
      "-1.9068755895501697e-05 [0.01380897]\n",
      "-0.029495333638465127 [0.54309607]\n",
      "-7.380900934970351e-06 [-0.00859122]\n",
      "-0.08633047422258677 [-0.92914194]\n",
      "-0.04175024188129015 [-0.6461443]\n",
      "-0.009112948437888591 [-0.3018766]\n",
      "-0.02332534280018672 [0.48296317]\n",
      "-0.04855818987870322 [0.69683707]\n",
      "-0.018430673827793953 [0.4293096]\n",
      "-0.0585594741456589 [0.7652416]\n",
      "-0.04441237763352923 [0.6664261]\n",
      "-0.03849506828845648 [-0.62044394]\n",
      "-0.020786400737689805 [0.45592105]\n",
      "-5.0055363653381606e-05 [0.02237306]\n",
      "-0.019249646193783578 [0.4387442]\n",
      "-0.008788840948490417 [-0.2964598]\n",
      "-0.058091412829577395 [0.7621772]\n",
      "-0.03664230262049593 [0.60532886]\n",
      "-0.00013639084395309503 [-0.03693113]\n",
      "-0.060922332141331026 [0.7805276]\n",
      "-0.04294692864633909 [-0.65533906]\n",
      "-0.05091527963867613 [0.71354944]\n",
      "-0.006740143587160574 [0.25961787]\n",
      "-0.08505473211246227 [0.9222512]\n",
      "-0.06803613357834735 [-0.8248402]\n",
      "-0.09959452806506307 [-0.9979706]\n",
      "-0.03414989752493547 [-0.58437914]\n",
      "-0.005423561205822325 [-0.2328854]\n",
      "-0.019881630586187173 [0.44588822]\n",
      "-0.00771863817067251 [-0.27782437]\n",
      "-1.7950155734824427e-06 [-0.00423676]\n",
      "-0.06616886497923247 [-0.81344247]\n",
      "-0.003105106205790609 [-0.17621312]\n",
      "-0.08873148746957327 [-0.9419739]\n",
      "-0.0021377769316188733 [0.14621139]\n",
      "-0.07360740636982542 [0.8579476]\n",
      "-0.01962420456558256 [-0.44299215]\n",
      "-0.025087826958589687 [-0.5008775]\n",
      "-0.02152563575913016 [-0.46395728]\n",
      "-0.017798271498325937 [0.42187998]\n",
      "-0.03980832781710575 [0.6309384]\n",
      "-0.003861710036154875 [-0.19651234]\n",
      "-0.00027985335146668707 [0.05290117]\n",
      "-0.0038160967061177335 [0.19534832]\n",
      "-0.05688212086918157 [0.75420237]\n",
      "-0.00017250916521738824 [0.04153422]\n",
      "-0.008944965710802055 [0.29908136]\n",
      "-0.010281908636449089 [0.32065415]\n",
      "-0.01798758354699368 [-0.4241177]\n",
      "-0.00891128374004504 [-0.29851773]\n",
      "-0.05872584772561176 [-0.7663279]\n",
      "-0.02419206623007 [0.4918543]\n",
      "-0.034323824158413174 [0.5858654]\n",
      "-0.00010424184791281294 [-0.03228651]\n",
      "-0.0013651837462532513 [-0.11684108]\n",
      "-0.035540659702849454 [0.5961599]\n",
      "-0.009519335563021869 [0.3085342]\n",
      "-0.03773057038517927 [0.61425215]\n",
      "-0.06959097689628493 [0.83421206]\n",
      "-0.019418635724893198 [0.4406658]\n",
      "-0.005616385978276051 [-0.23698916]\n",
      "-0.0065849934140388205 [-0.25661242]\n",
      "-0.02061672252615887 [-0.4540564]\n",
      "-0.08291255053126499 [0.9105633]\n",
      "-0.0701376059380209 [-0.837482]\n",
      "-0.05030169239731208 [-0.70923686]\n",
      "-2.2155338117348102e-05 [0.01488467]\n",
      "-0.005460914664681216 [0.233686]\n",
      "-0.09113361090972241 [0.95463926]\n",
      "-0.06259063978441191 [0.79114246]\n",
      "-0.00685489573015099 [0.26181856]\n",
      "-0.0214706228830587 [0.46336403]\n",
      "-0.09967307390232386 [0.99836403]\n",
      "-0.006749258011098292 [0.25979334]\n",
      "-0.08685628597299377 [0.9319672]\n",
      "-0.00022483153578269912 [0.0474164]\n",
      "-0.08108164125474247 [0.90045345]\n",
      "-0.007217179517443029 [-0.2686481]\n",
      "-0.09083673915688487 [-0.9530831]\n",
      "-0.0307086434066278 [0.5541538]\n",
      "-0.08923017894712758 [0.9446173]\n",
      "-0.009770811292492 [0.31258297]\n",
      "-0.008510102955898801 [-0.2917208]\n",
      "-0.09007203575091048 [0.9490629]\n",
      "-0.07243910415605229 [-0.85111165]\n",
      "-0.023897915696347027 [0.48885494]\n",
      "-0.04854374517542546 [0.6967334]\n",
      "-0.027372393174154297 [-0.5231863]\n",
      "-0.011280244944939089 [-0.33586076]\n",
      "-0.014646606197218049 [0.38270885]\n",
      "-0.0264592525957724 [-0.5143856]\n",
      "-0.02098951684768089 [0.45814317]\n",
      "-0.05350653482971701 [0.7314816]\n",
      "-0.015173501636340703 [-0.3895318]\n",
      "-0.018129604292109837 [-0.42578873]\n",
      "-0.002520944440291917 [0.15877482]\n",
      "-0.0373509017391882 [0.61115384]\n",
      "-0.0037908694503485663 [0.19470155]\n",
      "-0.09261238530942287 [0.9623533]\n",
      "-0.0006399617057806728 [-0.07999761]\n",
      "-0.05835202345663824 [0.76388496]\n",
      "-0.04329128487780168 [-0.65796113]\n",
      "-0.019455301588381248 [-0.44108164]\n",
      "-0.0888981059425337 [0.9428579]\n",
      "-0.061584760011101386 [-0.7847596]\n",
      "-0.03953110054414175 [0.6287376]\n",
      "-0.054218814875043014 [0.73633426]\n",
      "-0.005660691254014694 [0.23792207]\n",
      "-0.06606116558448641 [0.8127802]\n",
      "-0.0885339747406281 [-0.94092494]\n",
      "-0.027230246656458592 [0.5218261]\n",
      "-0.09103638178069993 [0.9541299]\n",
      "-0.040279869436048804 [0.63466424]\n",
      "-0.0050223051247272115 [-0.224105]\n",
      "-0.0852018306350729 [0.9230484]\n",
      "-0.0023424057857327264 [0.1530492]\n",
      "-0.03471284984621015 [0.5891761]\n",
      "-0.07090012521735255 [0.8420221]\n",
      "-1.6124443864668717e-05 [-0.01269821]\n",
      "-0.04368802015807347 [0.66096914]\n",
      "-0.03637995695034988 [-0.603158]\n",
      "-0.02272688966744321 [-0.47672728]\n",
      "-0.010085295798489824 [0.31757355]\n",
      "-0.07223810864743996 [-0.84993005]\n",
      "-0.029976168285685747 [-0.54750496]\n",
      "-0.09176248006543944 [-0.95792735]\n",
      "-0.03234846579044905 [0.5687571]\n",
      "-0.08123078692538144 [0.90128124]\n",
      "-0.06390835802449146 [0.79942703]\n",
      "-0.09000668829796724 [-0.94871855]\n",
      "-0.040072441180359776 [0.633028]\n",
      "-0.015055083130575131 [-0.3880088]\n",
      "-0.05465728811312012 [-0.7393057]\n",
      "-0.08587083685790874 [0.9266652]\n",
      "-0.0924615192577992 [0.96156913]\n",
      "-0.018753599934493437 [-0.43305427]\n",
      "-0.006006479517953545 [-0.2450812]\n",
      "-0.08473813359169072 [0.9205332]\n",
      "-0.0066203637311875955 [-0.25730067]\n",
      "-0.00972956029560379 [-0.31192243]\n",
      "-0.0018059033104300905 [0.1343839]\n",
      "-0.023311098364263573 [-0.48281568]\n",
      "-0.0737601007128447 [0.858837]\n",
      "-0.06797736542976054 [-0.8244839]\n",
      "-0.00964467287073525 [-0.31055874]\n",
      "-0.08562513519792106 [0.9253385]\n",
      "-0.08560190570961056 [0.925213]\n",
      "-0.08730618535060018 [0.9343778]\n",
      "-0.007861555743274096 [0.28038466]\n",
      "-0.02779906055093875 [-0.52724814]\n",
      "-0.02981932689508291 [0.54607075]\n",
      "-0.0653533745148721 [-0.80841434]\n",
      "-0.08156218248373968 [-0.90311784]\n",
      "-0.035113843597719095 [0.59256935]\n",
      "-0.08580818030655771 [-0.92632705]\n",
      "-0.00031393927938553473 [-0.05603028]\n",
      "-0.004162921062293124 [-0.20403238]\n",
      "-0.04931845358808005 [0.702271]\n",
      "-0.00011764728419011578 [0.03429975]\n",
      "-0.01435681846978163 [0.37890393]\n",
      "-0.000269420198311611 [0.0519057]\n",
      "-0.07419391218718943 [-0.8613589]\n",
      "-0.05048164356979079 [0.71050435]\n",
      "-0.0597853410677601 [-0.7732098]\n",
      "-0.08283597703059833 [-0.9101427]\n",
      "-0.017275526891689097 [-0.4156384]\n",
      "-0.05248334910220365 [0.7244539]\n",
      "-0.06472182099344118 [0.80449873]\n",
      "-0.013339044509033116 [-0.36522657]\n",
      "-0.09409058371634416 [0.970003]\n",
      "-0.08295702844755085 [0.9108075]\n",
      "-0.04781574233455821 [-0.6914893]\n",
      "-0.019591434567121625 [-0.44262213]\n",
      "-0.07677707635367917 [0.8762253]\n",
      "-0.054237434162587306 [0.7364607]\n",
      "-0.040067709801547835 [0.6329906]\n",
      "-0.06361661896155511 [0.79760027]\n",
      "-0.004861040972948794 [0.22047769]\n",
      "-0.08611138148455809 [0.9279622]\n",
      "-0.0019908382820176484 [-0.14109707]\n",
      "-0.02094094043540773 [0.45761272]\n",
      "-0.04228641543318226 [-0.65028006]\n",
      "-0.023640287717160292 [0.4862128]\n",
      "-0.04078715386346268 [0.6386482]\n",
      "-0.04723387223482725 [0.68726903]\n",
      "-0.03037803436163813 [0.5511627]\n",
      "-0.0006422098701919232 [-0.080138]\n",
      "-0.017075782760329707 [-0.41322854]\n",
      "-0.08983555359097616 [-0.9478162]\n",
      "-0.0009667033348135291 [0.09832107]\n",
      "-0.07229528445066223 [-0.85026634]\n",
      "-0.02628108302630814 [-0.5126508]\n",
      "-0.05494259054616216 [0.7412327]\n",
      "-0.03989626355704878 [0.6316349]\n",
      "-0.0701618181678331 [0.8376265]\n",
      "-0.02181535342847987 [-0.4670691]\n",
      "-0.008435815949130987 [0.29044476]\n",
      "-0.0055634595380311905 [0.23586987]\n",
      "-0.0019229731872067114 [0.13867131]\n",
      "-0.06040194317940859 [-0.7771869]\n",
      "-0.04176837586439888 [0.6462846]\n",
      "-0.051887556640020094 [-0.7203302]\n",
      "-0.004567152256357421 [0.21370897]\n",
      "-0.0017453670152774105 [0.13211234]\n",
      "-0.007072348686348562 [0.26593888]\n",
      "-0.02307221962267514 [-0.4803355]\n",
      "-0.06608696047301557 [0.81293887]\n",
      "-0.0513887827040449 [0.7168597]\n",
      "-0.0006037459661683898 [0.07770109]\n",
      "-0.0025347144467575914 [0.15920787]\n",
      "-0.019543859200519265 [-0.44208437]\n",
      "-0.006132372395460295 [-0.24763627]\n",
      "-0.0756502739450614 [0.86977166]\n",
      "-0.00046751618663611885 [-0.06837516]\n",
      "-0.09160184543793584 [0.95708853]\n",
      "-0.006164483966261103 [0.24828379]\n",
      "-3.861114157810569e-05 [-0.01964972]\n",
      "-0.0991050093123036 [-0.995515]\n",
      "-0.0026954645289060334 [0.1641787]\n",
      "-0.020379746058205583 [0.45143932]\n",
      "-0.09361504256927199 [0.96754867]\n",
      "-0.0026701282062583155 [0.16340527]\n",
      "-0.01886685297680657 [0.4343599]\n",
      "-0.015862773759819506 [-0.39828098]\n",
      "-0.0352055019256742 [0.59334224]\n",
      "-0.04934549795831487 [0.7024635]\n",
      "-0.09335868885892183 [-0.966223]\n",
      "-0.029996744187286952 [-0.54769284]\n",
      "-0.010866097810550458 [-0.32963765]\n",
      "-0.008181438525884132 [-0.28603214]\n",
      "-0.034125791270311366 [0.58417284]\n",
      "-0.07223313394283118 [0.8499008]\n",
      "-0.09261876393197532 [0.9623864]\n",
      "-0.027565802077005232 [0.52503145]\n",
      "-0.0017935180771895044 [-0.1339223]\n",
      "-0.08406382424033475 [0.91686326]\n",
      "-0.030072417345058968 [-0.54838324]\n",
      "-0.05892800378279653 [-0.7676458]\n",
      "-0.007050039902236538 [-0.2655191]\n",
      "-0.05759399556137055 [-0.7589071]\n",
      "-0.09341832849425238 [0.9665316]\n",
      "-0.01206570544726171 [0.34735724]\n",
      "-0.0004713607118766783 [0.06865571]\n",
      "-0.015860829562844094 [-0.39825657]\n",
      "-0.06423491633096355 [-0.8014669]\n",
      "-0.0038500058696300243 [0.19621432]\n",
      "-0.09204394357321953 [0.95939535]\n",
      "-0.02197422089977863 [0.4687667]\n",
      "-0.010435661855923685 [-0.32304275]\n",
      "-0.07677749417102611 [-0.8762277]\n",
      "-0.01725575548492211 [-0.41540048]\n",
      "-0.011300517136103229 [-0.33616242]\n",
      "-0.07900063828876683 [-0.88882303]\n",
      "-0.07991807850017417 [0.8939691]\n",
      "-0.0012068491785434399 [0.10985669]\n",
      "-0.02712960879990192 [0.5208609]\n",
      "-0.04606584884996643 [-0.67871827]\n",
      "-0.0028658283818441045 [-0.16928758]\n",
      "-0.05703012455089471 [0.7551829]\n",
      "-0.06246656849385915 [0.79035795]\n",
      "-0.020362092931590327 [0.45124376]\n",
      "-0.0001606014313987325 [-0.04007511]\n",
      "-0.005775040647652308 [-0.24031314]\n",
      "-0.0015028932345986735 [0.12259255]\n",
      "-0.07202141714488484 [0.8486543]\n",
      "-0.0010304011507461298 [0.10150868]\n",
      "-0.031094470520244857 [0.55762416]\n",
      "-0.0751155654190061 [-0.86669236]\n",
      "-0.005058009369065886 [-0.22490019]\n",
      "-0.034168939191710025 [-0.58454204]\n",
      "-0.04725642994067272 [0.6874331]\n",
      "-0.004353067207816453 [0.20864005]\n",
      "-0.026314877003543204 [0.5129803]\n",
      "-0.03424970049154332 [0.58523244]\n",
      "-0.08870630215186602 [0.94184023]\n",
      "-0.03516778363426774 [0.5930243]\n",
      "-0.016531963267221172 [0.40659517]\n",
      "-0.004607513006016562 [-0.21465118]\n",
      "-0.04966559301316842 [-0.7047382]\n",
      "-0.06780749564061495 [-0.82345307]\n",
      "-0.0004987214968511788 [0.07062022]\n",
      "-0.0133995137063053 [0.36605346]\n",
      "-0.002240326929086578 [-0.14967722]\n",
      "-0.0004277719975764649 [0.06540428]\n",
      "-0.04769900760202894 [0.6906447]\n",
      "-0.06695990039726817 [-0.8182903]\n",
      "-0.028119143564458684 [-0.53027487]\n",
      "-0.02467227805209973 [-0.49671197]\n",
      "-1.7079771674297172e-05 [0.01306896]\n",
      "-0.03591524493193141 [-0.5992933]\n",
      "-0.049155992006753024 [-0.70111334]\n",
      "-0.09827846216658145 [0.99135494]\n",
      "-0.021703801591649443 [0.4658734]\n",
      "-0.016199629682093077 [0.40248764]\n",
      "-0.03729727770484068 [0.610715]\n",
      "-0.019386964300237255 [0.4403063]\n",
      "-0.010778106561296942 [0.32830027]\n",
      "-0.022381360570823097 [0.47308943]\n",
      "-0.0800205565175375 [-0.8945421]\n",
      "-0.042258908264471984 [-0.6500685]\n",
      "-0.05295314079078004 [-0.7276891]\n",
      "-0.045785738375379026 [0.6766516]\n",
      "-0.06127609387790223 [0.7827905]\n",
      "-0.08651838500655665 [0.9301526]\n",
      "-0.004134048134579182 [-0.20332359]\n",
      "-0.07199448887932114 [0.84849566]\n",
      "-0.06321434015408159 [0.79507446]\n",
      "-0.07295781234990138 [0.85415345]\n",
      "-0.05720265236643094 [0.75632435]\n",
      "-0.07656404376808155 [-0.8750088]\n",
      "-0.07357465122885323 [-0.8577567]\n",
      "-0.06775608747494176 [0.82314086]\n",
      "-0.07199167697666874 [0.8484791]\n",
      "-0.02023135650313215 [-0.4497928]\n",
      "-0.0891255300379271 [-0.9440632]\n",
      "-0.0016604295848283936 [0.12885766]\n",
      "-0.05724332215341441 [-0.75659317]\n",
      "-0.027798180617628534 [-0.5272398]\n",
      "-0.01815360044471257 [-0.42607042]\n",
      "-0.0004317349875065324 [-0.06570654]\n",
      "-0.022996766325718544 [-0.47954944]\n",
      "-0.0514991403809578 [-0.717629]\n",
      "-0.04085380488309198 [0.6391698]\n",
      "-0.04255843303579674 [-0.65236825]\n",
      "-0.017132494330687198 [0.41391417]\n",
      "-0.010825960811140423 [-0.32902828]\n",
      "-0.04177660447545009 [0.64634824]\n",
      "-0.00042682560050357756 [-0.06533189]\n",
      "-0.00015291615446540036 [-0.0391045]\n",
      "-0.08118098486893502 [0.9010049]\n",
      "-0.08799957878302536 [0.9380809]\n",
      "-0.0033525244403777247 [-0.183099]\n",
      "-0.02340021404741757 [-0.48373768]\n",
      "-0.0536287621964803 [-0.7323166]\n",
      "-0.0015421348806584024 [0.12418272]\n",
      "-0.002561258413430445 [0.16003932]\n",
      "-0.01797378617717449 [-0.42395502]\n",
      "-0.002066705204182484 [-0.1437604]\n",
      "-0.09135236679469472 [0.9557843]\n",
      "-0.014275212989808585 [0.37782553]\n",
      "-0.08945104799895631 [0.94578564]\n",
      "-0.00024676699216939074 [0.04967565]\n",
      "-0.06896158180029631 [-0.8304311]\n",
      "-0.04816144980579793 [0.6939845]\n",
      "-0.0003939452989701664 [-0.06276506]\n",
      "-0.01596453631266037 [0.39955646]\n",
      "-0.01780894254773422 [0.42200643]\n",
      "-0.05812923433548037 [-0.7624253]\n",
      "-0.00974864134155986 [0.31222814]\n",
      "-0.03423687188324607 [0.5851228]\n",
      "-0.08506418729376151 [0.9223025]\n",
      "-0.018769436385264272 [0.43323708]\n",
      "-0.023835385657571352 [-0.48821497]\n",
      "-0.03486524465589049 [0.590468]\n",
      "-0.03839888819928916 [-0.61966836]\n",
      "-0.03139597268187231 [0.5603211]\n",
      "-0.09046718093424069 [-0.9511424]\n",
      "-0.043597973932543256 [-0.6602876]\n",
      "-0.005641831730764935 [-0.2375254]\n",
      "-0.00585528643165747 [-0.24197699]\n",
      "-0.01562998859940743 [-0.3953478]\n",
      "-0.013400022081864284 [0.3660604]\n",
      "-0.09705664014924231 [0.9851733]\n",
      "-0.06051926453406545 [0.7779413]\n",
      "-0.04643815076676994 [-0.68145543]\n",
      "-0.09276583139781316 [0.9631502]\n",
      "-0.09646003936672153 [-0.9821407]\n",
      "-0.05227036464627908 [0.72298247]\n",
      "-0.06795187239649891 [0.82432926]\n",
      "-0.04149954410509196 [0.6442014]\n",
      "-0.01470044673504143 [0.38341162]\n",
      "-0.05250571914960034 [0.7246083]\n",
      "-0.0800147342035018 [-0.89450955]\n",
      "-0.015516238078447576 [0.39390656]\n",
      "-0.002145438933263222 [0.14647317]\n",
      "-0.012299056729223512 [0.3507001]\n",
      "-0.06513236247944612 [-0.80704623]\n",
      "-0.02282447524521212 [0.47774968]\n",
      "-0.08519271990270597 [-0.922999]\n",
      "-0.07910363984451721 [0.8894023]\n",
      "-0.03332255493251637 [-0.5772569]\n",
      "-0.0003060715228822578 [0.05532373]\n",
      "-0.01983256518663348 [0.44533768]\n",
      "-0.043764956613871676 [0.6615509]\n",
      "-8.207524806600266e-06 [-0.00905954]\n",
      "-0.0008420078469706439 [0.09176099]\n",
      "-0.02220142919955146 [0.47118393]\n",
      "-0.043576094626041596 [-0.6601219]\n",
      "-0.0783838903656843 [0.8853468]\n",
      "-0.050072694287882774 [0.7076206]\n",
      "-0.0988310249296692 [0.99413794]\n",
      "-0.06134342111840994 [-0.7832204]\n",
      "-0.002051199186671604 [0.14322008]\n",
      "-0.08562260914168895 [-0.92532486]\n",
      "-0.08162340946609029 [-0.90345675]\n",
      "-0.06594859722794269 [-0.8120874]\n",
      "-0.059002352053227375 [0.7681299]\n",
      "-0.0010797054115583794 [-0.10390887]\n",
      "-0.008468487296384187 [0.29100665]\n",
      "-0.07319606878575123 [-0.855547]\n",
      "-0.06941481085252832 [-0.8331555]\n",
      "-0.008199692664626302 [0.28635105]\n",
      "-0.04042305793520882 [0.6357913]\n",
      "-0.024715815602022764 [0.49715003]\n",
      "-0.02939608347397247 [-0.54218155]\n",
      "-0.055173970493328645 [-0.74279183]\n",
      "-0.0853214926922906 [0.92369634]\n",
      "-0.03146155329662328 [-0.560906]\n",
      "-0.08777862259926827 [-0.93690246]\n",
      "-0.09316441912462246 [-0.9652172]\n",
      "-0.0001464666778759005 [0.03827097]\n",
      "-0.036293969843269734 [-0.60244477]\n",
      "-0.07463269275125449 [0.86390215]\n",
      "-0.0842836251635859 [0.91806114]\n",
      "-0.005275238297878105 [-0.22967887]\n",
      "-0.03488495643668479 [-0.5906349]\n",
      "-0.05580876910446478 [-0.74705267]\n",
      "-0.0012392775270819779 [-0.11132284]\n",
      "-0.0426943794139234 [-0.65340936]\n",
      "-0.023117660967386745 [0.4808083]\n",
      "-0.007489151057289068 [0.27366313]\n",
      "-0.013168919906982879 [-0.36289006]\n",
      "-0.006209691251040739 [-0.24919252]\n",
      "-0.08633458355468662 [-0.92916405]\n",
      "-0.022797951773086213 [0.477472]\n",
      "-0.0930465515225265 [-0.9646064]\n",
      "-0.006796491852709608 [0.26070082]\n",
      "-0.0007237054329167769 [0.08507088]\n",
      "-0.06961259809830977 [-0.83434165]\n",
      "-0.02449923740519502 [-0.49496704]\n",
      "-0.07204827961506909 [0.8488126]\n",
      "-0.05855952888001781 [0.765242]\n",
      "-0.0019565551910707634 [-0.13987692]\n",
      "-0.04665643549220136 [0.68305516]\n",
      "-0.041338370402287695 [-0.6429492]\n",
      "-0.00014119765788248723 [0.03757628]\n",
      "-0.0527648759407473 [-0.72639436]\n",
      "-0.04676361356123984 [0.68383926]\n",
      "-0.07801230834446393 [0.88324577]\n",
      "-0.013457541567704201 [-0.36684522]\n",
      "-0.03226733165283555 [0.5680434]\n",
      "-0.004717529457598979 [-0.21719874]\n",
      "-0.05614992662749643 [-0.74933255]\n",
      "-0.095472781660607 [0.97710174]\n",
      "-0.08125595157872 [-0.90142083]\n",
      "-0.09009767444474939 [0.94919795]\n",
      "-0.0522818883797882 [0.72306216]\n",
      "-0.02420167723195199 [0.491952]\n",
      "-0.08977665104801567 [0.9475054]\n",
      "-0.0017396434037664221 [0.13189554]\n",
      "-1.6294708235849882e-07 [-0.00127651]\n",
      "-0.008271054339602646 [-0.2875944]\n",
      "-0.05554671070627002 [-0.74529666]\n",
      "-0.0056150511832495425 [0.23696099]\n",
      "-0.0012896191406664371 [-0.1135614]\n",
      "-0.04958056795217658 [0.7041347]\n",
      "-0.00022559650607967415 [-0.047497]\n",
      "-0.08539178139671755 [0.92407674]\n",
      "-0.007619922659893863 [0.27604207]\n",
      "-0.05165319913208464 [0.7187016]\n",
      "-0.027542636636644604 [-0.5248108]\n",
      "-0.08091163566971318 [-0.89950895]\n",
      "-0.03461618220706129 [0.5883552]\n",
      "-0.0006483183090865374 [0.08051822]\n",
      "-0.05661175709884994 [-0.75240785]\n",
      "-0.0794953027390907 [0.8916014]\n",
      "-0.0018977402510302 [0.1377585]\n",
      "-0.007061018040553169 [0.26572576]\n",
      "-0.04600134610114424 [-0.6782429]\n",
      "-0.07216813405104859 [0.8495183]\n",
      "-0.019719981606346783 [-0.44407186]\n",
      "-0.010452990705380217 [-0.32331085]\n",
      "-0.04880538609286447 [-0.6986085]\n",
      "-0.016076019724700075 [0.40094912]\n",
      "-0.05820342274530646 [-0.7629117]\n",
      "-0.08499496774008755 [0.92192715]\n",
      "-0.0912956570779798 [-0.9554876]\n",
      "-0.01423655857175854 [0.37731364]\n",
      "-0.05592265803944799 [-0.74781454]\n",
      "-0.020883408880719403 [0.4569837]\n",
      "-0.06704034295279691 [-0.8187817]\n",
      "-0.09492176851570698 [0.97427803]\n",
      "-0.04513816560637771 [0.6718494]\n",
      "-0.0018512489706108194 [-0.13606061]\n",
      "-0.04113638852600197 [-0.64137655]\n",
      "-0.06180132332080035 [-0.7861382]\n",
      "-0.034779141415896574 [0.5897384]\n",
      "-0.005344930344341159 [-0.23119105]\n",
      "-0.0014029680815861368 [-0.11844695]\n",
      "-0.05736712470554864 [-0.7574109]\n",
      "-0.08462859751006171 [-0.919938]\n",
      "-0.03986043035525633 [0.6313512]\n",
      "-0.018163689048258738 [-0.4261888]\n",
      "-0.03689196270570392 [0.60738754]\n",
      "-0.06441891906461593 [-0.802614]\n",
      "-0.037323556898071784 [-0.6109301]\n",
      "-0.005192712846771053 [-0.22787525]\n",
      "-0.04971902178475638 [0.70511717]\n",
      "-0.07231089467870931 [-0.8503581]\n",
      "-0.08284793388290589 [0.9102084]\n",
      "-0.038330795291494725 [-0.6191187]\n",
      "-0.0407277462480554 [0.63818294]\n",
      "-0.04730342264338425 [0.68777484]\n",
      "-0.06698203582317462 [-0.81842554]\n",
      "-0.09089359031373193 [0.9533813]\n",
      "-0.08732829697317222 [-0.9344961]\n",
      "-0.016100642138511125 [-0.40125605]\n",
      "-0.08028690289518324 [-0.8960296]\n",
      "-0.07824968843923195 [0.88458854]\n",
      "-0.030213911931784666 [-0.5496718]\n",
      "-0.005193211333664772 [-0.22788619]\n",
      "-0.0030214973738168283 [-0.17382455]\n",
      "-0.08969140424643599 [-0.94705546]\n",
      "-0.0075812258267578874 [-0.27534026]\n",
      "-0.009065852739462699 [-0.30109555]\n",
      "-0.09761400652505473 [0.987998]\n",
      "-0.03748961547967298 [0.61228764]\n",
      "-0.08711391567792114 [-0.93334836]\n",
      "-0.03721612482477212 [-0.6100502]\n",
      "-0.03378754819692773 [0.5812706]\n",
      "-0.08361459661189806 [0.9144102]\n",
      "-0.047667422327380395 [-0.690416]\n",
      "-0.024627394546946936 [-0.49625996]\n",
      "-0.08008495732997858 [-0.894902]\n",
      "-0.0049919896288825654 [0.22342761]\n",
      "-0.06662548614104367 [0.81624436]\n",
      "-0.05519666759914941 [0.7429446]\n",
      "-0.001921977328953517 [-0.1386354]\n",
      "-0.0782628176607446 [-0.88466275]\n",
      "-0.0899559831660156 [-0.9484513]\n",
      "-0.0227383481038701 [-0.47684744]\n",
      "-0.005440872175874945 [0.23325677]\n",
      "-0.01147628326262442 [-0.33876663]\n",
      "-0.05950550704610045 [0.7713981]\n",
      "-0.06547115373399635 [-0.8091425]\n",
      "-0.006069659224695045 [0.24636678]\n",
      "-0.005112369545134699 [-0.2261055]\n",
      "-0.0447125545484596 [0.66867447]\n",
      "-0.0026092731350475743 [0.16153245]\n",
      "-0.007642488712953366 [-0.2764505]\n",
      "-0.08700305434686584 [-0.9327543]\n",
      "-0.021574846507525083 [-0.4644873]\n",
      "-0.07857261715060737 [0.88641196]\n",
      "-0.05617849716363708 [-0.74952316]\n",
      "-3.657901204157099e-09 [0.00019126]\n",
      "-0.03976240053145972 [-0.63057435]\n",
      "-0.04252645292130097 [0.6521231]\n",
      "-0.00022723677447116788 [-0.04766936]\n",
      "-0.01163969980722337 [-0.34117004]\n",
      "-0.06587833308118576 [-0.8116547]\n",
      "-0.09571490971184496 [0.97833997]\n",
      "-0.026098929343030264 [-0.5108711]\n",
      "-0.019296804718354467 [-0.43928128]\n",
      "-0.07835566054070889 [0.8851873]\n",
      "-0.03023993790391302 [0.5499085]\n",
      "-0.019630420651105852 [0.4430623]\n",
      "-0.07914505863482191 [0.8896351]\n",
      "-0.08039469407382427 [0.8966309]\n",
      "-0.001870392429236123 [-0.13676229]\n",
      "-0.08488434315239744 [0.921327]\n",
      "-0.058310925226053106 [-0.7636159]\n",
      "-0.0947735930865079 [0.9735173]\n",
      "-0.010241428196157277 [-0.3200223]\n",
      "-0.02960119113615747 [-0.54406977]\n",
      "-0.046001629086578434 [0.678245]\n",
      "-0.0004352302865445745 [0.06597199]\n",
      "-0.08294451002474582 [-0.91073877]\n",
      "-0.08551679095306533 [0.9247529]\n",
      "-0.06074782828638945 [0.77940893]\n",
      "-0.07300679744522008 [0.85444015]\n",
      "-0.08109456579661725 [0.9005252]\n",
      "-0.02668780365500112 [0.5166024]\n",
      "-0.0343017860050864 [0.58567727]\n",
      "-0.08066645840325606 [0.8981451]\n",
      "-0.03353832653827773 [0.57912284]\n",
      "-0.0016793051798472903 [0.12958801]\n",
      "-0.0017939631230788678 [-0.13393891]\n",
      "-0.08712252770845944 [-0.9333945]\n",
      "-0.011926629127150168 [0.34534952]\n",
      "-0.03183598256503082 [-0.56423384]\n",
      "-0.05192706438003292 [-0.72060436]\n",
      "-0.0113128351338454 [-0.33634558]\n",
      "-0.09688342037488021 [0.98429376]\n",
      "-0.07318211733471039 [0.8554655]\n",
      "-0.026888530264730905 [-0.5185415]\n",
      "-0.006130349666990754 [-0.24759543]\n",
      "-0.0028576927844881084 [0.16904712]\n",
      "-0.00011677965163634646 [-0.03417304]\n",
      "-0.024845710767282814 [-0.49845472]\n",
      "-0.03468803314007154 [0.5889655]\n",
      "-0.08717181584788847 [0.9336585]\n",
      "-0.05639150388086059 [0.75094277]\n",
      "-0.03519051542971283 [-0.59321594]\n",
      "-0.009424370035326125 [-0.30699137]\n",
      "-0.05581970567009762 [-0.74712586]\n",
      "-0.034023950936046175 [-0.58330053]\n",
      "-0.0915446591221155 [-0.95678973]\n",
      "-0.06911190850011942 [0.8313357]\n",
      "-0.011501478600242 [0.3391383]\n",
      "-0.04960172293650089 [-0.7042849]\n",
      "-0.007274409732362131 [-0.26971114]\n",
      "-0.03755765875723682 [-0.61284304]\n",
      "-0.013548428326512242 [0.3680819]\n",
      "-0.07698213132454193 [0.8773946]\n",
      "-0.0021914931751099154 [0.14803693]\n",
      "-0.09104346799189358 [0.954167]\n",
      "-7.171339797529403e-05 [0.02677936]\n",
      "-0.0006409775028982934 [0.08006107]\n",
      "-0.04972193858865381 [0.70513785]\n",
      "-0.01555897279903462 [-0.39444864]\n",
      "-0.08824361095962595 [0.9393807]\n",
      "-0.02987688059884022 [0.5465975]\n",
      "-0.006795713372110957 [-0.2606859]\n",
      "-0.01755383238261752 [0.41897294]\n",
      "-0.056254622435162466 [0.7500308]\n",
      "-0.05143560634570008 [0.7171862]\n",
      "-0.0006491146306600249 [-0.08056765]\n",
      "-0.07830560863738789 [0.88490456]\n",
      "-0.06861395421759796 [0.8283354]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-451c34711de4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-9a380d4f95dd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mlogstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1676\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1677\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1678\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/traceback.py\u001b[0m in \u001b[0;36mformat_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mformat_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/traceback.py\u001b[0m in \u001b[0;36mformat_list\u001b[0;34m(extracted_list)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mwhose\u001b[0m \u001b[0msource\u001b[0m \u001b[0mtext\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \"\"\"\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mStackSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/traceback.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                     \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'    {name} = {value}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_RECURSIVE_CUTOFF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0m_RECURSIVE_CUTOFF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "        \n",
    "    mu, std = actor(torch.Tensor(state))\n",
    "    a = np.tanh(get_action(mu,std))\n",
    "    state, reward, done, _ = env.step(a)\n",
    "    print(reward,a)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
